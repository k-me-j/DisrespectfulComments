{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "551cb1d8-2113-42b5-ba7c-62f4de1755c3",
   "metadata": {},
   "source": [
    "# < 버트 사전학습 모형 가져오기 >\n",
    "- [케라스로 버트 학습하기](https://github.com/kimwoonggon/publicservant_AI/blob/master/03_%EC%BC%80%EB%9D%BC%EC%8A%A4%EB%A1%9C_%EB%B2%84%ED%8A%B8_%EB%B9%A0%EB%A5%B4%EA%B2%8C_%EB%8F%8C%EB%A0%A4%EB%B3%B4%EA%B8%B0_With_%EB%84%A4%EC%9D%B4%EB%B2%84_%EC%98%81%ED%99%94_%EA%B0%90%EC%84%B1%EB%B6%84%EC%84%9D_TUTORIAL.ipynb) 참고 사이트\n",
    "- https://github.com/google-research/bert 에 접속하셔서 ```BERT-Base, Multilingual Cased: 104 languages, 12-layer, 768-hidden, 12-heads, 110M parameters``` 파일을 다운"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c51299b-a2cb-41f3-bd97-cabcbe393f70",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "# !pip install keras-bert  # 케라스에서 Bert 활용을 쉽게 만들어주는 모듈 keras-bert\n",
    "# !pip install keras-radam  # Adam optimizer의 수정판인 keras-radam 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b0c45bb-6a27-46ac-a74c-5a6ed23cf1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import keras as keras\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras import Input, Model\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import codecs\n",
    "from tqdm import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18d5a100-1f7c-4f4b-b66f-b8cd31f54088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "# tf.compat.v1.logging.set_verbosity(tf.logging.ERROR)  # 워닝 뜨는거 감추려고 해주는거 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b78f5fd0-9de5-438c-90dc-ecf1fbd9ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_bert import load_trained_model_from_checkpoint, load_vocabulary\n",
    "from keras_bert import Tokenizer\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "\n",
    "from keras_radam import RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09288337-b57b-4865-95a4-db52ad676725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bert_model.ckpt.data-00000-of-00001',\n",
       " '.ipynb_checkpoints',\n",
       " 'bert_model.ckpt.meta',\n",
       " 'multi_cased_L-12_H-768_A-12.zip',\n",
       " 'bert_model.ckpt.index',\n",
       " 'vocab.txt',\n",
       " 'bert_config.json']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485fd1af-4cdd-4977-8f04-dac7b56bba6b",
   "metadata": {},
   "source": [
    "# df 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "66c2412d-8144-4e8f-a703-3b6230e43806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"</td>\n",
       "      <td>김태리 정말 연기잘해 진짜</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만...</td>\n",
       "      <td>공효진 발연기나이질생각이읍던데 왜계속주연일까</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"</td>\n",
       "      <td>누구처럼 돈만 밝히는 저급인생은 살아가지마시길~~ 행복은 머니순이 아니니깐 작은거에...</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"</td>\n",
       "      <td>일본 축구 져라</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의...</td>\n",
       "      <td>난 절대로 임현주 욕하는인간이랑은 안논다 @.@</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0         \"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"   \n",
       "1  \"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만...   \n",
       "2             \"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"   \n",
       "3               \"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"   \n",
       "4  \"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의...   \n",
       "\n",
       "                                             comment    bias  hate  \n",
       "0                                     김태리 정말 연기잘해 진짜    none  none  \n",
       "1                           공효진 발연기나이질생각이읍던데 왜계속주연일까    none  hate  \n",
       "2  누구처럼 돈만 밝히는 저급인생은 살아가지마시길~~ 행복은 머니순이 아니니깐 작은거에...  others  hate  \n",
       "3                                           일본 축구 져라    none  none  \n",
       "4                         난 절대로 임현주 욕하는인간이랑은 안논다 @.@    none  none  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv', encoding = 'UTF-8-SIG')\n",
    "# test_df = pd.read_csv('data/test.csv', encoding = 'UTF-8-SIG')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7481a599-1212-4fa8-88a3-ecbb8b9a2ba5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 확인용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9247d273-8c01-46f0-8227-f96864e26a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8367"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "480542bd-7b57-4e8a-b46c-3ed9688d39a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias classes:  ['none' 'others' 'gender']\n",
      "hate classes:  ['none' 'hate']\n"
     ]
    }
   ],
   "source": [
    "print(\"bias classes: \", df.bias.unique())\n",
    "print(\"hate classes: \", df.hate.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4674f3cf-a729-419e-8c25-0e029e5d415d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>hate</th>\n",
       "      <th>hate</th>\n",
       "      <th>none</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>1216</td>\n",
       "      <td>83</td>\n",
       "      <td>1299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>2068</td>\n",
       "      <td>3422</td>\n",
       "      <td>5490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>others</th>\n",
       "      <td>1437</td>\n",
       "      <td>141</td>\n",
       "      <td>1578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>4721</td>\n",
       "      <td>3646</td>\n",
       "      <td>8367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "hate    hate  none   All\n",
       "bias                    \n",
       "gender  1216    83  1299\n",
       "none    2068  3422  5490\n",
       "others  1437   141  1578\n",
       "All     4721  3646  8367"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가능한 모든 조합들의 개수 확인\n",
    "pd.crosstab(df.bias, df.hate, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f39db45-b4df-4e1f-b957-dbcf7354951f",
   "metadata": {},
   "source": [
    "# 두 라벨의 가능한 모든 조합 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9d9affbb-9253-4b07-8c87-aba9bfebb379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['none', 'none'],\n",
       "       ['none', 'hate'],\n",
       "       ['others', 'none'],\n",
       "       ['others', 'hate'],\n",
       "       ['gender', 'none'],\n",
       "       ['gender', 'hate']], dtype=object)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinations = np.array(np.meshgrid(df.bias.unique(), df.hate.unique())).T.reshape(-1,2)\n",
    "\n",
    "combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c1f37d-732d-43fc-a281-fd502162f7e2",
   "metadata": {},
   "source": [
    "## bias, hate 컬럼을 합친 리스트 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a84f1881-615b-4221-be82-461e5ac595b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['none', 'none'], dtype=object),\n",
       " array(['none', 'hate'], dtype=object),\n",
       " array(['others', 'hate'], dtype=object),\n",
       " array(['none', 'none'], dtype=object),\n",
       " array(['none', 'none'], dtype=object)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_hate = list(np.array([df['bias'].values, df['hate'].values]).T.reshape(-1,2))\n",
    "\n",
    "bias_hate[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c831e01-ddb5-4370-b210-08cb63159bc6",
   "metadata": {},
   "source": [
    "## 정수 코드로 라벨 만들기"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a6f03e2a-206b-4260-89b1-12b2589bf56c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "for i, arr in enumerate(bias_hate):\n",
    "    for idx, elem in enumerate(combinations):\n",
    "        # print(i, idx)\n",
    "        if np.array_equal(elem, arr):\n",
    "    #     #     labels.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "784342e1-92c7-4f7d-8281-2042b91b354a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"</td>\n",
       "      <td>김태리 정말 연기잘해 진짜</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만...</td>\n",
       "      <td>공효진 발연기나이질생각이읍던데 왜계속주연일까</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"</td>\n",
       "      <td>누구처럼 돈만 밝히는 저급인생은 살아가지마시길~~ 행복은 머니순이 아니니깐 작은거에...</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"</td>\n",
       "      <td>일본 축구 져라</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의...</td>\n",
       "      <td>난 절대로 임현주 욕하는인간이랑은 안논다 @.@</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0         \"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"   \n",
       "1  \"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만...   \n",
       "2             \"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"   \n",
       "3               \"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"   \n",
       "4  \"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의...   \n",
       "\n",
       "                                             comment    bias  hate  label  \n",
       "0                                     김태리 정말 연기잘해 진짜    none  none      0  \n",
       "1                           공효진 발연기나이질생각이읍던데 왜계속주연일까    none  hate      1  \n",
       "2  누구처럼 돈만 밝히는 저급인생은 살아가지마시길~~ 행복은 머니순이 아니니깐 작은거에...  others  hate      3  \n",
       "3                                           일본 축구 져라    none  none      0  \n",
       "4                         난 절대로 임현주 욕하는인간이랑은 안논다 @.@    none  none      0  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "\n",
    "for i, arr in enumerate(bias_hate):\n",
    "    for idx, elem in enumerate(combinations):\n",
    "        if np.array_equal(elem, arr):\n",
    "            labels.append(idx)\n",
    "\n",
    "df['label'] = labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb16052-5242-407d-a8ab-c8e42832f2d0",
   "metadata": {},
   "source": [
    "# bert 훈련을 위한 사전 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6f365a37-02a8-4324-8fbb-8fb2978f3539",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LR = 1e-6\n",
    "\n",
    "pretrained_path =\"bert\"\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
    "vocab_path = os.path.join(pretrained_path, 'vocab.txt')\n",
    "\n",
    "DATA_COLUMN = \"comment\"\n",
    "LABEL_COLUMN = \"label\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00405377-2704-40db-99c8-e172e94337c1",
   "metadata": {},
   "source": [
    "분석할 문장이 토큰화가 되고, 그 다음에는 인덱스(숫자)로 변경되어서 버트 신경망에 인풋으로 들어감."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bd37841c-99be-4cf4-a549-e090b627dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict = {}  # vocab.txt에 있는 단어에 인덱스를 추가해주는 token_dict\n",
    "\n",
    "with codecs.open(vocab_path, 'r', 'utf8') as reader:\n",
    "    for line in reader:\n",
    "        token = line.strip()\n",
    "        if \"_\" in token:\n",
    "            token = token.replace(\"_\",\"\")\n",
    "            token = \"##\" + token\n",
    "        token_dict[token] = len(token_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c47758a-bc36-44f6-a701-cc567231ede6",
   "metadata": {},
   "source": [
    "Tokenizer 클래스를 상속받아서 inherit_Tokennizer라는 클래스를 재정의하고 _tokenize 함수를 새로 작성합니다. 왜 상속을 해서 함수를 새로 만들어야 하냐면, 만약 원래 클래스를 그대로 사용하면 입력한 문장이 \"완전자모분리\"됩니다. 예를 들어서 \"인공지능 할 수 있다\" 라는 문장이 있다면 원래 \"인,##공,##지,##능,할,수,있다\"로 분해가 되어야 하는데, ㅇ,##ㅣ,##ㄴ,ㄱ,##ㅗ,##ㅇ,ㅈ,##ㅣ,##ㄴ,##ㅡ,##ㅇ 이런 식으로 토큰화가 됩니다.\n",
    "\n",
    "두칸 아래에서 보시겠지만, inherit_Tokenizer클래스는 문장을 토큰화하는 기능을 합니다.\n",
    "\n",
    "BERT의 토큰화는 단어를 분리하는 토큰화 방식입니다. wordpiece(단어조각?) 방식이라고 하는데, 이는 한국어를 형태소로 꼭 변환해야 할 문제를 해결해주며, 의미가 있는 단어는 밀접하게 연관이 되게 하는 장점까지 갖추고 있습니다.\n",
    "\n",
    "단어의 첫 시작은 ##가 붙지 않지만, 단어에 포함되면서 단어의 시작이 아닌 부분에는 ##가 붙는 것이 특징입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9913b91a-dad4-4c14-b600-65439eb78414",
   "metadata": {},
   "outputs": [],
   "source": [
    "class inherit_Tokenizer(Tokenizer):\n",
    "    def _tokenize(self, text):\n",
    "        if not self._cased:\n",
    "            text = text\n",
    "            text = text.lower()\n",
    "            \n",
    "        spaced = ''\n",
    "        \n",
    "        for ch in text:\n",
    "            if self._is_punctuation(ch) or self._is_cjk_character(ch):\n",
    "                spaced += ' ' + ch + ' '\n",
    "            elif self._is_space(ch):\n",
    "                spaced += ' '\n",
    "            elif ord(ch) == 0 or ord(ch) == 0xfffd or self._is_control(ch):\n",
    "                continue\n",
    "            else:\n",
    "                spaced += ch\n",
    "                \n",
    "        tokens = []\n",
    "        \n",
    "        for word in spaced.strip().split():\n",
    "            tokens += self._word_piece_tokenize(word)\n",
    "            \n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "15199297-d7b0-4127-8b8d-502a98bcc1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = inherit_Tokenizer(token_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6005876-d4d0-4277-ae8a-fef65f74e54f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 토큰화가 잘 되었는지 확인해 봅니다. \n",
    "- 버트 모형은 문장 앞에 꼭 [CLS]라는 문자가 위치하고, [SEP]라는 문자가 끝에 위치합니다.\n",
    "- [CLS]는 문장의 시작, [SEP]는 문장의 끝을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a3283642-bdad-4cc4-85cb-5de03f812728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '케',\n",
       " '##라',\n",
       " '##스로',\n",
       " '버',\n",
       " '##트',\n",
       " '해',\n",
       " '##보',\n",
       " '##기',\n",
       " '정',\n",
       " '##말',\n",
       " '재',\n",
       " '##밌',\n",
       " '##음',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"케라스로 버트 해보기 정말 재밌음.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c285b8d-da4e-4c43-afe0-acf4897d15a8",
   "metadata": {},
   "source": [
    "# 감성분석 데이터를 버트 모형의 입력에 맞게 변형해주는 함수를 정의\n",
    "함수 내부에 tokenizer.encode 함수가 버트 모형을 토큰화해주고 토큰화 된 단어를 인덱스에 맞게 숫자로 바꿔주게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "56797b26-5540-46ee-b46f-8f2a0824bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(data_df):\n",
    "    global tokenizer\n",
    "    indices, targets = [], []\n",
    "    \n",
    "    for i in tqdm(range(len(data_df))):\n",
    "        ids, segments = tokenizer.encode(data_df[DATA_COLUMN][i], max_len=SEQ_LEN)\n",
    "        indices.append(ids)\n",
    "        targets.append(data_df[LABEL_COLUMN][i])\n",
    "    items = list(zip(indices, targets))\n",
    "    \n",
    "    indices, targets = zip(*items)\n",
    "    indices = np.array(indices)\n",
    "    \n",
    "    return [indices, np.zeros_like(indices)], np.array(targets)\n",
    "\n",
    "\n",
    "def load_data(data_df):\n",
    "    # data_df = data_df\n",
    "    \n",
    "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n",
    "\n",
    "    data_x, data_y = convert_data(data_df)\n",
    "\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4ae26c53-d6fb-453d-9805-4c97e4ae0fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a size for your train set \n",
    "train_size = int(0.7 * len(df))\n",
    "\n",
    "# Split your dataset \n",
    "train_df = df[:train_size]\n",
    "test_df = df[train_size:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "dd806496-a071-411d-bdb3-1043b37e527d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 5856/5856 [00:00<00:00, 8660.30it/s]\n",
      "100% 2511/2511 [00:00<00:00, 8885.19it/s]\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = load_data(train_df)\n",
    "test_x, test_y = load_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5d18cc59-7c9e-42bf-bedd-a137f246fbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[   101,   8935,  83616, ...,      0,      0,      0],\n",
       "        [   101,   8896, 119449, ...,      0,      0,      0],\n",
       "        [   101,   9032,  17196, ...,      0,      0,      0],\n",
       "        ...,\n",
       "        [   101,    187,  19528, ...,      0,      0,      0],\n",
       "        [   101,   9764,  53639, ...,      0,      0,      0],\n",
       "        [   101,   9670,  14523, ...,      0,      0,      0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb2c406-07de-432d-af4b-cda4ce571d80",
   "metadata": {},
   "source": [
    "- 사전학습된 버트 모델의 인풋은 문장 토큰화가 숫자로 바뀐 것과, 앞문장인지 뒷문장인지 알려주는 문장 순서 벡터가 들어갑니다. 우리는 문장 하나를 가지고만 훈련할 것이므로 순서 벡터는 모두 0으로 통일합니다.\n",
    "\n",
    "- 그리고 파인튜닝 시에는 문장 안에 일부 단어를 가리는 마스킹은 사용하지 않습니다.\n",
    "  - Fine Tuning 이란? - 기존에 학습되어져 있는 모델을 기반으로 아키텍쳐를 새로운 목적(나의 이미지 데이터에 맞게)변형하고 이미 학습된 모델 Weights로 부터 학습을 업데이트하는 방법을 말한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597bdb55-45fd-4604-9314-09d9e661cac7",
   "metadata": {},
   "source": [
    "# bert input = token, segment, position\n",
    "1. 토큰 : 문장을 토크나이징 한 후, 인덱스 번호를 매긴 것\n",
    "2. 세그먼트 : 예를 들어 문장이 두 개가 있다면, 앞의 문장과 뒤의 문장을 구분하는 것. 파인튜닝 과정에서 앞뒷문장 구분 안할거면 전부 0으로 지정\n",
    "3. 포지션 임베딩 : 단순히 단어의 위치를 의미. 단어 순서에 따라서 자동으로 부여됨\n",
    "-> 토큰, 세그먼트, 포지션을 인풋으로 버트 모형에 넣으면 기하학적인 문장 공간으로 임베딩이 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b0aa6621-532a-4cd0-9110-9c83201976d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_convert_data(data):\n",
    "    global tokenizer\n",
    "    indices = []\n",
    "    segs = []\n",
    "    \n",
    "    for i in tqdm(range(len(data))):\n",
    "        print(tokenizer.tokenize(data[i]))\n",
    "        ids, segments = tokenizer.encode(data[i], max_len=SEQ_LEN)\n",
    "        print('segments : ', segments)\n",
    "        indices.append(ids)\n",
    "        segs.append(segments)\n",
    "        \n",
    "    indices = np.array(indices)\n",
    "    segs = np.array(segs)\n",
    "    return [indices, segs]\n",
    "\n",
    "\n",
    "def sentence_load_data(sentences):  # sentence는 List로 받음\n",
    "    data_x = sentence_convert_data(sentences)\n",
    "    return data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bb68c98c-07a1-4eeb-b65a-29c745220f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 2/2 [00:00<00:00, 702.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t ['[CLS]', '케', '##라', '##스로', '버', '##트', '해', '##보', '##기', '정', '##말', '재', '##밌', '##음', '.', '근', '##데', '어', '##렵', '##다', '[SEP]']\n",
      "segments :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\t ['[CLS]', '케', '##라', '##스', '쉬', '##워', '?', '쉬', '##워', '!', '[SEP]']\n",
      "segments :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[   101,   9806,  17342,  94980,   9336,  15184,   9960,  30005,\n",
       "          12310,   9670,  89523,   9659,    100,  32158,    119,   8926,\n",
       "          28911,   9546, 118879,  11903,    102,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0],\n",
       "        [   101,   9806,  17342,  12605,   9469,  69592,    136,   9469,\n",
       "          69592,    106,    102,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0]]),\n",
       " array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_load_data([\"케라스로 버트 해보기 정말 재밌음. 근데 어렵다\", \"케라스 쉬워? 쉬워!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f70a593-c5b8-44ee-a8eb-bccb75e2a7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
