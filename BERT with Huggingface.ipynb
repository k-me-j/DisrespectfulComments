{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "551cb1d8-2113-42b5-ba7c-62f4de1755c3",
   "metadata": {},
   "source": [
    "# < 버트 사전학습 모형 가져오기 >\n",
    "- [허깅페이스와 버트 학습하기](https://github.com/kimwoonggon/publicservant_AI/blob/master/1_(HuggingFace)%EB%84%A4%EC%9D%B4%EB%B2%84_%EC%98%81%ED%99%94_%ED%8F%89%EA%B0%80_%EA%B8%8D%EB%B6%80%EC%A0%95_%EB%B6%84%EC%84%9D.ipynb) 참고 사이트\n",
    "\n",
    "- [참고 블로그](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=winddori2002&logNo=222022178447)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b0c45bb-6a27-46ac-a74c-5a6ed23cf1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import *\n",
    "# import transformers\n",
    "\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d846c1d9-233c-45a5-bf5d-e5e5df544c4d",
   "metadata": {},
   "source": [
    "os.listdir('bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7baae1-da92-4cdd-b8a1-fc30e2eebdc4",
   "metadata": {},
   "source": [
    "### 기본 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a756135b-eda0-4052-8bf7-41ace19e2467",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 128\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "# 긍부정 문장을 포함하고 있는 칼럼\n",
    "DATA_COLUMN = \"comment\"\n",
    "\n",
    "# target = 칼럼\n",
    "LABEL_COLUMN = \"label\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485fd1af-4cdd-4977-8f04-dac7b56bba6b",
   "metadata": {},
   "source": [
    "# df 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66c2412d-8144-4e8f-a703-3b6230e43806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"</td>\n",
       "      <td>김태리 정말 연기잘해 진짜</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만...</td>\n",
       "      <td>공효진 발연기나이질생각이읍던데 왜계속주연일까</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"</td>\n",
       "      <td>누구처럼 돈만 밝히는 저급인생은 살아가지마시길~~ 행복은 머니순이 아니니깐 작은거에...</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"</td>\n",
       "      <td>일본 축구 져라</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의...</td>\n",
       "      <td>난 절대로 임현주 욕하는인간이랑은 안논다 @.@</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0         \"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"   \n",
       "1  \"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만...   \n",
       "2             \"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"   \n",
       "3               \"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"   \n",
       "4  \"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의...   \n",
       "\n",
       "                                             comment    bias  hate  \n",
       "0                                     김태리 정말 연기잘해 진짜    none  none  \n",
       "1                           공효진 발연기나이질생각이읍던데 왜계속주연일까    none  hate  \n",
       "2  누구처럼 돈만 밝히는 저급인생은 살아가지마시길~~ 행복은 머니순이 아니니깐 작은거에...  others  hate  \n",
       "3                                           일본 축구 져라    none  none  \n",
       "4                         난 절대로 임현주 욕하는인간이랑은 안논다 @.@    none  none  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv', encoding = 'UTF-8-SIG')\n",
    "# test_df = pd.read_csv('data/test.csv', encoding = 'UTF-8-SIG')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7481a599-1212-4fa8-88a3-ecbb8b9a2ba5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 확인용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fce6a1fd-79aa-49ff-a78c-3efcfa586d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8367, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "480542bd-7b57-4e8a-b46c-3ed9688d39a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias classes:  ['none' 'others' 'gender']\n",
      "hate classes:  ['none' 'hate']\n"
     ]
    }
   ],
   "source": [
    "print(\"bias classes: \", df.bias.unique())\n",
    "print(\"hate classes: \", df.hate.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4674f3cf-a729-419e-8c25-0e029e5d415d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>hate</th>\n",
       "      <th>hate</th>\n",
       "      <th>none</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>1216</td>\n",
       "      <td>83</td>\n",
       "      <td>1299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>2068</td>\n",
       "      <td>3422</td>\n",
       "      <td>5490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>others</th>\n",
       "      <td>1437</td>\n",
       "      <td>141</td>\n",
       "      <td>1578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>4721</td>\n",
       "      <td>3646</td>\n",
       "      <td>8367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "hate    hate  none   All\n",
       "bias                    \n",
       "gender  1216    83  1299\n",
       "none    2068  3422  5490\n",
       "others  1437   141  1578\n",
       "All     4721  3646  8367"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가능한 모든 조합들의 개수 확인\n",
    "pd.crosstab(df.bias, df.hate, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f39db45-b4df-4e1f-b957-dbcf7354951f",
   "metadata": {},
   "source": [
    "# 두 라벨의 가능한 모든 조합 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d9affbb-9253-4b07-8c87-aba9bfebb379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['none', 'none'],\n",
       "       ['none', 'hate'],\n",
       "       ['others', 'none'],\n",
       "       ['others', 'hate'],\n",
       "       ['gender', 'none'],\n",
       "       ['gender', 'hate']], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinations = np.array(np.meshgrid(df.bias.unique(), df.hate.unique())).T.reshape(-1,2)\n",
    "\n",
    "combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c1f37d-732d-43fc-a281-fd502162f7e2",
   "metadata": {},
   "source": [
    "## bias, hate 컬럼을 합친 리스트 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a84f1881-615b-4221-be82-461e5ac595b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['none', 'none'], dtype=object),\n",
       " array(['none', 'hate'], dtype=object),\n",
       " array(['others', 'hate'], dtype=object),\n",
       " array(['none', 'none'], dtype=object),\n",
       " array(['none', 'none'], dtype=object)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_hate = list(np.array([df['bias'].values, df['hate'].values]).T.reshape(-1,2))\n",
    "\n",
    "bias_hate[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c831e01-ddb5-4370-b210-08cb63159bc6",
   "metadata": {},
   "source": [
    "## 정수 코드로 라벨 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "784342e1-92c7-4f7d-8281-2042b91b354a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"</td>\n",
       "      <td>김태리 정말 연기잘해 진짜</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만...</td>\n",
       "      <td>공효진 발연기나이질생각이읍던데 왜계속주연일까</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"</td>\n",
       "      <td>누구처럼 돈만 밝히는 저급인생은 살아가지마시길~~ 행복은 머니순이 아니니깐 작은거에...</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"</td>\n",
       "      <td>일본 축구 져라</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의...</td>\n",
       "      <td>난 절대로 임현주 욕하는인간이랑은 안논다 @.@</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0         \"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"   \n",
       "1  \"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만...   \n",
       "2             \"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"   \n",
       "3               \"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"   \n",
       "4  \"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의...   \n",
       "\n",
       "                                             comment    bias  hate  label  \n",
       "0                                     김태리 정말 연기잘해 진짜    none  none      0  \n",
       "1                           공효진 발연기나이질생각이읍던데 왜계속주연일까    none  hate      1  \n",
       "2  누구처럼 돈만 밝히는 저급인생은 살아가지마시길~~ 행복은 머니순이 아니니깐 작은거에...  others  hate      3  \n",
       "3                                           일본 축구 져라    none  none      0  \n",
       "4                         난 절대로 임현주 욕하는인간이랑은 안논다 @.@    none  none      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "\n",
    "for i, arr in enumerate(bias_hate):\n",
    "    for idx, elem in enumerate(combinations):\n",
    "        if np.array_equal(elem, arr):\n",
    "            labels.append(idx)\n",
    "\n",
    "df['label'] = labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb16052-5242-407d-a8ab-c8e42832f2d0",
   "metadata": {},
   "source": [
    "# bert input 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1df1e0-d92e-470b-8d78-e773a5d01117",
   "metadata": {},
   "source": [
    "- 한글 데이터를 분석하려면, 100개가 넘는 언어에 대해 훈련된 버트를 사용해야 함\n",
    "- multilingual BERT를 사용할 예정.\n",
    "- \n",
    "모델을 로드하기에 앞서, 토크나이저를 불러오기 : huggingface로 쉽게 토크나이저를 불러오기 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5928a4a-e1d9-435c-8d79-33a988862969",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46880f3b0081fda494a4e15b05787692aa4c1e21e0ff2428ba8b14d4eda0784d.b33e51591f94f17c238ee9b1fac75b96ff2678cbaed6e108feadb3449d18dc24\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b6debd-1776-4176-86de-c47163765fb1",
   "metadata": {},
   "source": [
    "### 가장 기초에 속하는 tokenizer 사용 방법 \n",
    "#### tokenizer.encode => 문장을 버트 모델의 인풋 토큰값으로 바꿔줌\n",
    "#### tokenizer.tokenize => 문장을 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de08ea78-a5c7-4959-ae87-76d6189f76e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 9356, 11018, 31605, 31605, 110589, 71568, 118913, 11018, 9576, 119281, 9786, 79940, 23811, 40364, 9520, 23160, 102]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(\"보는내내 그대로 들어맞는 예측 카리스마 없는 악역\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "389ed5c0-02e7-4dc3-a98c-7644b024d4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['보', '##는', '##내', '##내', '그대로', '들어', '##맞', '##는', '예', '##측', '카', '##리스', '##마', '없는', '악', '##역']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize(\"보는내내 그대로 들어맞는 예측 카리스마 없는 악역\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597bdb55-45fd-4604-9314-09d9e661cac7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## bert input = token, segment, mask\n",
    "1. 토큰 : 문장을 토크나이징 한 후, 인덱스 번호를 매긴 것, 단어를 단어사전의 위치값으로 표현\n",
    "2. 세그먼트 : 예를 들어 문장이 두 개가 있다면, 앞의 문장과 뒤의 문장을 구분하는 것. 파인튜닝 과정에서 앞뒷문장 구분 안할거면 전부 0으로 지정\n",
    "3. 마스크 : 문장이 유효한 값인지, 아니면 유효하지 않은 값이라 패딩 값으로 채운 것인지를 나타냄 (문장이 유효한 값이면 1, 유효하지 않은 값이면 0으로 채움)\n",
    "-> 토큰, 세그먼트, 마스크를 인풋으로 버트 모형에 넣으면 버트 모형에 맞게 고차원으로 임베딩이 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd18f761-f116-460f-aea3-87717f6bf62c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 9665, 119183, 10622, 9641, 119185, 66815, 42428, 119, 25805, 98199, 119088, 10892, 42428, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(\"전율을 일으키는 영화. 다시 보고싶은 영화\", max_length=64, pad_to_max_length=True))\n",
    "# 문장마다 문장 길이는 다르지만, 버트의 인풋 길이는 일정해야 하므로, 버트에서 지정한 문장 길이를 초과하면 패딩값인 0을 채우게 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9b82c7c-e53a-4876-88bb-cd1f26eb8cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# 마스크 인풋 : 토큰 인풋에서 패딩이 아닌 부분은 1, 패딩인 부분은 0\n",
    "valid_num = len(tokenizer.encode(\"전율을 일으키는 영화. 다시 보고싶은 영화\"))\n",
    "print(valid_num * [1] + (128 - valid_num) * [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95867161-0dfe-4f8a-bff8-41d2302bc425",
   "metadata": {},
   "source": [
    "## 정리\n",
    "- 버트 인풋 = 토큰, 세그먼트, 마스크\n",
    "```\n",
    "\"전율을 일으키는 영화. 다시 보고싶은 영화\" 라는 문장을 가지고 예를 들면,\n",
    "\n",
    "토큰 인풋 : [101, 9665, 119183, 10622, 9641, 119185, 66815, 42428, 119, 25805, 98199, 119088, 10892, 42428, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "세그먼트 인풋 : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "마스크 인풋 : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "문장들을 버트 인풋으로 바꾸면 ```문장 -> 토큰 인풋, 세그먼트 인풋, 마스크 인풋``` 으로 변환됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c285b8d-da4e-4c43-afe0-acf4897d15a8",
   "metadata": {},
   "source": [
    "# 버트 모형의 입력에 맞게 변형해주는 함수\n",
    "함수 내부에 tokenizer.encode 함수가 버트 모형을 토큰화해주고 토큰화 된 단어를 인덱스에 맞게 숫자로 바꿔줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56797b26-5540-46ee-b46f-8f2a0824bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(data_df):\n",
    "    global tokenizer\n",
    "    SEQ_LEN = 128  # 버트에 들어갈 인풋의 길이\n",
    "    tokens, masks, segments, targets = [], [], [], []\n",
    "    \n",
    "    for i in tqdm(range(len(data_df))):\n",
    "        # token : 문장을 토큰화함\n",
    "        token = tokenizer.encode(data_df[DATA_COLUMN][i], \n",
    "                                 max_length=SEQ_LEN, \n",
    "                                 truncation=True, \n",
    "                                 padding='max_length')\n",
    "       \n",
    "        # 마스크는 토큰화한 문장에서 패딩이 아닌 부분은 1, 패딩인 부분은 0으로 통일\n",
    "        num_zeros = token.count(0)\n",
    "        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros\n",
    "        \n",
    "        # 문장의 전후관계를 구분해주는 세그먼트. 문장이 1개밖에 없으므로 모두 0\n",
    "        segment = [0]*SEQ_LEN\n",
    "\n",
    "        # 버트 인풋으로 들어가는 token, mask, segment를 tokens, segments에 각각 저장\n",
    "        tokens.append(token)\n",
    "        masks.append(mask)\n",
    "        segments.append(segment)\n",
    "        \n",
    "        # 정답을 targets 변수에 저장해 줌\n",
    "        targets.append(data_df[LABEL_COLUMN][i])\n",
    "\n",
    "    # tokens, masks, segments, 정답 변수 targets를 numpy array로 지정    \n",
    "    tokens = np.array(tokens)\n",
    "    masks = np.array(masks)\n",
    "    segments = np.array(segments)\n",
    "    targets = np.array(targets)\n",
    "\n",
    "    return [tokens, masks, segments], targets\n",
    "\n",
    "\n",
    "# 위에 정의한 convert_data 함수를 불러오는 함수를 정의\n",
    "def load_data(data_df):\n",
    "    \n",
    "    # data_df = pandas_dataframe\n",
    "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n",
    "    data_df[LABEL_COLUMN] = data_df[LABEL_COLUMN].astype(int)\n",
    "    \n",
    "    data_x, data_y = convert_data(data_df)\n",
    "    \n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "226308dd-e545-4780-91c1-948ebfe5881b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset:  7530\n",
      "Validation dataset:  837\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "                                                         \n",
    "train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "print(\"Train dataset: \", len(train_df))\n",
    "print(\"Validation dataset: \", len(test_df))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "516750d7-5e02-4c5f-b8e1-53667e7c0186",
   "metadata": {},
   "source": [
    "# 데이터셋 나눠주기\n",
    "train_size = int(0.7 * len(df))\n",
    "\n",
    "train_df = df[:train_size]\n",
    "test_df = df[train_size:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96020086-048f-4444-bb37-160d8663b2ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 7530/7530 [00:02<00:00, 3343.15it/s]\n",
      "100% 837/837 [00:00<00:00, 3370.89it/s]\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = load_data(train_df)  # train 데이터를 버트 인풋에 맞게 변환\n",
    "test_x, test_y = load_data(test_df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "afabb162-6d9d-418f-b407-f2b6219f25f5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d18813-3d57-4fc5-9939-796a41670c3a",
   "metadata": {},
   "source": [
    "### huggingface에서는 [토큰 인풋, 마스크 인풋, 세그먼트 인풋] 순서!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b73af12-5e09-48d0-94c8-506c9ab81466",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tf_model.h5 from cache at /root/.cache/huggingface/transformers/879ba3c37de5c396bee982a9383f64cf08c9cc966d66742254a3904e6719357f.53d9b251a2a9d5d86139b64555b5e8deb0a20fc53f8a5ee958ddbb4506125a0b.h5\n",
      "Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# 토큰 인풋, 마스크 인풋, 세그먼트 인풋 정의\n",
    "token_inputs = tf.keras.layers.Input((SEQ_LEN,), \n",
    "                                     dtype=tf.int32, \n",
    "                                     name='input_word_ids')\n",
    "mask_inputs = tf.keras.layers.Input((SEQ_LEN,), \n",
    "                                    dtype=tf.int32, \n",
    "                                    name='input_masks')\n",
    "segment_inputs = tf.keras.layers.Input((SEQ_LEN,), \n",
    "                                       dtype=tf.int32, \n",
    "                                       name='input_segment')\n",
    "\n",
    "# 인풋이 [토큰, 마스크, 세그먼트]인 모델 정의\n",
    "bert_outputs = model([token_inputs, mask_inputs, segment_inputs])\n",
    "# 버트 아웃풋의 텐서의 shape은 [batch_size, 문장의 길이, 768]임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cad06b8e-94b3-46d0-9841-11ef8be6921f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'tf_bert_model_1')>, pooler_output=<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_bert_model_1')>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49bd51ed-2a22-4a2d-bc6a-55b6c176bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_outputs = bert_outputs[1]\n",
    "\n",
    "sentiment_first = tf.keras.layers.Dense(6, \n",
    "                                        activation='softmax', \n",
    "                                        kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(bert_outputs)\n",
    "\n",
    "sentiment_model = tf.keras.Model([token_inputs, mask_inputs, segment_inputs], sentiment_first)\n",
    "\n",
    "sentiment_model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-6), \n",
    "                        loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "                        metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "84e4e141-4827-431a-9920-3ce72d9ded47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_bert_model_1')>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1618a854-7dd3-4803-87ad-db58b3cb7884",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_word_ids (InputLayer)    [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_masks (InputLayer)       [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_segment (InputLayer)     [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model_1 (TFBertModel)  TFBaseModelOutputWi  177853440   ['input_word_ids[0][0]',         \n",
      "                                thPoolingAndCrossAt               'input_masks[0][0]',            \n",
      "                                tentions(last_hidde               'input_segment[0][0]']          \n",
      "                                n_state=(None, 128,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 6)            4614        ['tf_bert_model_1[0][1]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 177,858,054\n",
      "Trainable params: 177,858,054\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 구조 확인\n",
    "sentiment_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a913dd89-7b80-4426-a84a-2d6338433e36",
   "metadata": {},
   "source": [
    "# 버트 모형을 리턴하는 함수를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c16dfb38-e0a3-496d-aca3-6defea98877f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tensorflow_addons/optimizers/rectified_adam.py:120: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "# Rectified Adam 옵티마이저 사용\n",
    "opt = tfa.optimizers.RectifiedAdam(lr=1.0e-5, \n",
    "                                   weight_decay=0.0025, \n",
    "                                   warmup_proportion=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce690663-4c37-459f-83ce-99f65871dc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentiment_bert():\n",
    "    # 버트 pretrained 모델 로드\n",
    "    model = TFBertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "    \n",
    "    # 토큰 인풋, 마스크 인풋, 세그먼트 인풋 정의\n",
    "    token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids')\n",
    "    mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks')\n",
    "    segment_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment')\n",
    "    \n",
    "    # 인풋 순서가 [토큰, 마스크, 세그먼트]인 모델 정의\n",
    "    bert_outputs = model([token_inputs, mask_inputs, segment_inputs])\n",
    "\n",
    "    bert_outputs = bert_outputs[1]\n",
    "    sentiment_first = tf.keras.layers.Dense(6, \n",
    "                                            activation='softmax', \n",
    "                                            kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(bert_outputs)\n",
    "    sentiment_model = tf.keras.Model([token_inputs, mask_inputs, segment_inputs], sentiment_first)\n",
    "\n",
    "    sentiment_model.compile(optimizer=opt, loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "    return sentiment_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a183e5-5678-4a85-a68e-47054f83b788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6890b22-80bb-459d-a5d1-43c0aa01b1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e597a870-c602-485a-b7ef-37b455affad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
